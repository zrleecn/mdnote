# 机器学习



## 简介

机器学习是一类算法的总称，这些算法企图从大量历史数据中挖掘出其中隐含的规律，并用于预测或者分类，更具体的说，机器学习可以看作是寻找一个函数，输入是样本数据，输出是期望的结果，只是这个函数过于复杂，以至于不太方便形式化表达。需要注意的是，机器学习的目标是使学到的函数很好地适用于“新样本”，而不仅仅是在训练样本上表现很好。学到的函数适用于新样本的能力，称为泛化（Generalization）能力。

## 机器学习库和框架

tensorflow

## 书籍

![](http://libs.zrlee.cn/image/b3a4c225-9831-4eb8-8f20-b8a4528660ab.png)

![](http://libs.zrlee.cn/image/f11710ea-1928-41ae-9c73-d8ca14f848b7.png)

熟悉机器学习各类算法的原理

掌握算法的使用 能够结合场景解决实际问题

掌握使用机器学习算法库和框架的技能

## 概要

- 特征工程
- 模型、策略、优化
- 分类 回归和聚类
- TensorFlow
- 神经网络
- 图像识别
- 自然语言处理

## 数据集的组成

机器学习的数据: 文件csv

## 数据结构

特征值 + 目标值

有些数据可以没有目标值

## 特征工程

### 定义

特征工程指的是把原始数据转变为模型的训练数据的过程，它的目的就是获取更好的训练数据特征，使得机器学习模型逼近这个上限。特征工程能使得模型的性能得到提升，有时甚至在简单的模型上也能取得不错的效果 

### 意义

特征工程在机器学习中占有非常重要的作用，一般认为括特征构建、特征提取、特征选择三个部分。特征构建比较麻烦，需要一定的经验。 特征提取与特征选择都是为了从原始特征中找出最有效的特征。它们之间的区别是特征提取强调通过**特征转换**的方式得到一组具有明显物理或统计意义的特征；而特征选择是从特征集合中挑选一组具有明显物理或统计意义的**特征子集**。两者都能帮助减少特征的维度、数据冗余，特征提取有时能发现更有意义的特征属性，特征选择的过程经常能表示出每个特征的重要性对于模型构建的重要性。本文主要尝试总结几个常用的特征提取和特征选择的方法。 

### scikit-learn 库

- python语言机器学习工具
- 包括许多知名的机器学习算法的实现

#### 安装

安装前提不需要有numpy 和pandas 库

```shell
pip install Scikit-learn
```

#### 使用

```python
import sklearn
```

### 数据特征的抽取

![](http://libs.zrlee.cn/image/36d94752-8f93-48c5-85bd-2091a014e1c3.png)

#### scikit特征抽取API

#### 字典特征抽取

1. 实例化DictVectorizer
2. 调用fit_transform方法输入数据并转换  注意返回格式

```python
[
    {'city': '北京', 'temperature': 10},
    {'city': '上海', 'temperature': 12},
    {'city': '广州', 'temperature': 25},
]
```



```python
  from sklearn.feature_extraction import DictVectorizer


def dicvector():
    """
    字典特征抽取
    :return:
    """
    # 实例化
    dict_vectorizer = DictVectorizer()
    data = dict_vectorizer.fit_transform([
        {'city': '北京', 'temperature': 10},
        {'city': '上海', 'temperature': 12},
        {'city': '广州', 'temperature': 25},
    ])
    print(data)
    return None


if __name__ == '__main__':
    dicvector()

  # 输出结果  
  (0, 1)	1.0
  (0, 3)	10.0
  (1, 0)	1.0
  (1, 3)	12.0
  (2, 2)	1.0
  (2, 3)	25.0
```

```python
from sklearn.feature_extraction import DictVectorizer


def dicvector():
    """
    字典特征抽取
    :return:
    """
    # 实例化
    dict_vectorizer = DictVectorizer()
    data = dict_vectorizer.fit_transform([
        {'city': '北京', 'temperature': 10},
        {'city': '上海', 'temperature': 12},
        {'city': '广州', 'temperature': 25},
    ])
    # print(data)
    print(dict_vectorizer.get_feature_names())
    return None


if __name__ == '__main__':
    dicvector()
['city=上海', 'city=北京', 'city=广州', 'temperature']
```

#### 文本特征抽取

```python
from sklearn.feature_extraction.text import CountVectorizer

def dicvector():
    """
    字典特征抽取
    :return:
    """
    # 实例化
    dict_vectorizer = DictVectorizer()
    data = dict_vectorizer.fit_transform([
        {'city': '北京', 'temperature': 10},
        {'city': '上海', 'temperature': 12},
        {'city': '广州', 'temperature': 25},
    ])
    # 统计所有词 重复的只看做一次 词的列表
    print(dict_vectorizer.get_feature_names())
    # 对每篇文章 在词列表中进行统计每个词出现的次数 单个字母不统计
    print(data)
    return None

```

中文需要分词 

```python
pip install jieba
```

```python
import jieba 
jieba.cut("中文文本")
```

```python

def countvec():
    """
    对文本进行特征值化
    :return:
    """
    cv = CountVectorizer()
    s1 = "如果你得罪了老板，失去的只是一份工作；如果你得罪了客户，" \
    "失去的不过是一份订单；是的，世上只有一个人可以得罪：你给她脸色看，你冲她发牢骚"
    s2 = "，你大声顶撞她，甚至当 着她的面摔碗，她都不会记恨你，原因很简单，因为她是你的母亲。"

    c1 = list(jieba.cut(s1))
    c2 = list(jieba.cut(s2))

    data = cv.fit_transform([' '.join(c1), ' '.join(c2)])
    print(cv.get_feature_names())
    print(data.toarray())

```



#### tf_idf

![](http://libs.zrlee.cn/image/aa107be5-29b0-4713-be64-ac4179cd5d8e.png)





![](http://libs.zrlee.cn/image/f8789cd8-6afa-4201-b4a7-644a356a85dd.png)

```python
def tfidfvec():
    """

    :return:
    """
    s1 = "如果你得罪了老板，失去的只是一份工作；如果你得罪了客户，" \
         "失去的不过是一份订单；是的，世上只有一个人可以得罪：你给她脸色看，你冲她发牢骚"
    s2 = "，你大声顶撞她，甚至当 着她的面摔碗，她都不会记恨你，原因很简单，因为她是你的母亲。"

    c1 = list(jieba.cut(s1))
    c2 = list(jieba.cut(s2))
    tf = TfidfVectorizer()
    data = tf.fit_transform([' '.join(c1), ' '.join(c2)])
    print(tf.get_feature_names())
    print(data.toarray())
```



### 数据的特征预处理

#### 特征预处理归一化

对数据进行处理。通过特定的统计方法（数学方法） 将数据转换成算法要求的数据。

特点：通过对原始数据进行变换把数据映射到(默认[0,1])之间

公式: 
$$
X' = (x-min)/(max-min)   , X'' = X' * (mx-mi) + mi
$$
注: 作用于每一列，max为一列的最大值，min为一列的最小值，那么X'' 为最终结果，mx mi分别是指定区间的区间 默认值mx为1 mi为0

比如下面的数据

特征1				特征2				特征3				特征4

| 90   | 2    | 10   | 40   |
| ---- | ---- | ---- | ---- |
| 60   | 4    | 15   | 45   |
| 75   | 3    | 13   | 46   |

第一列第一行X' = (90-60)/(90 -60) = 1  X'' = 1*(1-0) + 0 = 1

第一列第二行X' = (60-60)/(90-60) = 0  X'' = 0*(1-0) + 0 = 0

### 数据的降维





